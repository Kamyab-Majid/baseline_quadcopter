{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of rl-baselines-zoo.ipynb","provenance":[{"file_id":"https://github.com/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/rl-baselines-zoo.ipynb","timestamp":1621447586388}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XJy9QoDC7XA7"},"source":["# RL Baselines3 Zoo: Training in Colab\n","\n","\n","\n","Github Repo: [https://github.com/DLR-RM/rl-baselines3-zoo](https://github.com/DLR-RM/rl-baselines3-zoo)\n","\n","Stable-Baselines3 Repo: [https://github.com/DLR-RM/rl-baselines3-zoo](https://github.com/DLR-RM/stable-baselines3)\n","\n","\n","# Install Dependencies\n","\n"]},{"cell_type":"code","metadata":{"id":"AXVDDlTn02M9"},"source":["!apt-get install swig cmake ffmpeg freeglut3-dev xvfb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kDjF3qRg7oGH"},"source":["## Clone RL Baselines3 Zoo Repo"]},{"cell_type":"code","metadata":{"id":"SCjGikdT1DFy"},"source":["!git clone --recursive https://github.com/DLR-RM/rl-baselines3-zoo"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"REMQlh-ezyVt"},"source":["%cd /content/rl-baselines3-zoo/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5tmD_QTBqTMb"},"source":["### Install pip dependencies"]},{"cell_type":"code","metadata":{"id":"OWIDzgJTqShY"},"source":["!pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6gJ-pAbF7zRZ"},"source":["## Train an RL Agent\n","\n","\n","The train agent can be found in the `logs/` folder.\n","\n","Here we will train A2C on CartPole-v1 environment for 100 000 steps. \n","\n","\n","To train it on Pong (Atari), you just have to pass `--env PongNoFrameskip-v4`\n","\n","Note: You need to update `hyperparams/algo.yml` to support new environments. You can access it in the side panel of Google Colab. (see https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory)"]},{"cell_type":"code","metadata":{"id":"9bIR_N7R11XI"},"source":["!python train.py --algo a2c --env CartPole-v1 --n-timesteps 100000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-fHBq73665yD"},"source":["#### Evaluate trained agent\n","\n","\n","You can remove the `--folder logs/` to evaluate pretrained agent."]},{"cell_type":"code","metadata":{"id":"Bw8YuEgU6bT3"},"source":["!python enjoy.py --algo a2c --env CartPole-v1 --no-render --n-timesteps 5000 --folder logs/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w5Il2J0VHPLC"},"source":["#### Tune Hyperparameters\n","\n","We use [Optuna](https://optuna.org/) for optimizing the hyperparameters.\n","\n","Tune the hyperparameters for PPO, using a tpe sampler and median pruner, 2 parallels jobs,\n","with a budget of 1000 trials and a maximum of 50000 steps"]},{"cell_type":"code","metadata":{"id":"w2sC22eGHTH-"},"source":["!python train.py --algo ppo --env MountainCar-v0 -n 50000 -optimize --n-trials 1000 --n-jobs 2 --sampler tpe --pruner median"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xVm9QPNVwKXN"},"source":["### Record  a Video"]},{"cell_type":"code","metadata":{"id":"MPyfQxD5z26J"},"source":["# Set up display; otherwise rendering will fail\n","import os\n","os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n","os.environ['DISPLAY'] = ':1'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ip3AauLzwNGP"},"source":["!python -m utils.record_video --algo a2c --env CartPole-v1 --exp-id 0 -f logs/ -n 1000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qBuUfnzI8DN6"},"source":["### Display the video"]},{"cell_type":"code","metadata":{"id":"ZC3OTfpf8CXu"},"source":["import base64\n","from pathlib import Path\n","\n","from IPython import display as ipythondisplay\n","\n","def show_videos(video_path='', prefix=''):\n","  \"\"\"\n","  Taken from https://github.com/eleurent/highway-env\n","\n","  :param video_path: (str) Path to the folder containing videos\n","  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n","  \"\"\"\n","  html = []\n","  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n","      video_b64 = base64.b64encode(mp4.read_bytes())\n","      html.append('''<video alt=\"{}\" autoplay \n","                    loop controls style=\"height: 400px;\">\n","                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n","                </video>'''.format(mp4, video_b64.decode('ascii')))\n","  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKOjFuwK9HI0"},"source":["show_videos(video_path='logs/videos/', prefix='a2c')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RjdpP0HE8D2p"},"source":["### Continue Training\n","\n","Here, we will continue training of the previous model"]},{"cell_type":"code","metadata":{"id":"zgMZQJJF6u1C"},"source":["!python train.py --algo a2c --env CartPole-v1 --n-timesteps 50000 -i logs/a2c/CartPole-v1_1/CartPole-v1.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GSaoyiAE8cVj"},"source":["!python enjoy.py --algo a2c --env CartPole-v1 --no-render --n-timesteps 1000 --folder logs/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jL9u4I1H-48O"},"source":[""],"execution_count":null,"outputs":[]}]}